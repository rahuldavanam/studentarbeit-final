{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fad60d00-b06b-4582-a91d-61c6f98c4fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import carla\n",
    "import numpy as np\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torchvision \n",
    "from torch import nn\n",
    "import queue\n",
    "import time\n",
    "from image_processing import *\n",
    "import os\n",
    "\n",
    "# Initialize latest image path\n",
    "disk_path = 'G:/carla_data/'\n",
    "\n",
    "frame_id = 0\n",
    "starting_time = 0\n",
    "IMG_WIDTH = 640\n",
    "IMG_HEIGHT = 480"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e8043660-c6fc-4630-ad73-1964e5f5385d",
   "metadata": {},
   "source": [
    "def image_maker(image_data):\n",
    "    '''\n",
    "        Takes in the image data from the camera and converts it into an image readable by the model\n",
    "        Args: \n",
    "        image_data = The raw data that the camera takes\n",
    "        \n",
    "    '''\n",
    "    i = np.array(image.raw_data)\n",
    "    i2 = i.reshape((IMG_HEIGHT, IMG_WIDTH, 4))\n",
    "    i3 = i2[:, :, :3]\n",
    "    return i3/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab951a78-94a3-452b-87db-bcc6a417e8c7",
   "metadata": {},
   "source": [
    "## Changing the map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb20bd0-c389-4513-aec2-3864c58287b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "time-out of 5000ms while waiting for the simulator, make sure the simulator is ready and connected to localhost:2000",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m client \u001b[38;5;241m=\u001b[39m carla\u001b[38;5;241m.\u001b[39mClient(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m2000\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Load a new map if you want to\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m world \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_world\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTown04\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: time-out of 5000ms while waiting for the simulator, make sure the simulator is ready and connected to localhost:2000"
     ]
    }
   ],
   "source": [
    "# Connects the client with the server\n",
    "client = carla.Client('localhost', 2000)\n",
    "\n",
    "# Load a new map if you want to\n",
    "world = client.load_world('Town04') # Set the fog=0 for this map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303f1112-3b2a-42f8-a175-329a352f7d3b",
   "metadata": {},
   "source": [
    "### Image preprocessing for model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ce216cc-11aa-4f38-a8d4-89137bd21716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f18ca2-81a1-44a6-97b6-16961485243b",
   "metadata": {},
   "source": [
    "### Loading the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ada5d22-76be-4346-a043-3df7dd23a474",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: carla_models\\model_checkpoint_v6.pth\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the model architecture (ResNet-50 in this case)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = torchvision.models.resnet18(weights=None)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "# Define the path where the model is saved\n",
    "MODEL_PATH = Path(\"carla_models\")\n",
    "MODEL_NAME = \"model_checkpoint_v6.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# Load the state dict\n",
    "print(f\"Loading model from: {MODEL_SAVE_PATH}\")\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f6b21b7-6adc-4dab-8d24-992d3e44e27a",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import torchinfo\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
    "        verbose=0,\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060b2a3-7700-4afb-90c0-1c9542d6ceaa",
   "metadata": {},
   "source": [
    "### Prediction of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b87f4928-608a-465c-8e22-09ac1f7815c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess the image and predict the throttle and steer\n",
    "def predict_control(image):\n",
    "    #processed_image = frame_processor(image)\n",
    "    cropped_processed_image = region_selection(image)\n",
    "    pil_image = Image.fromarray(cropped_processed_image)\n",
    "    #path = f\"G:/output_pictures/{time.time()}.png\"\n",
    "    #pil_image.save(path)  # DEBUGGING - To check how the tensor input to the model looks like.\n",
    "    input_tensor = preprocess(pil_image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        steer = output.cpu().numpy()\n",
    "        throttle = 0.4\n",
    "        #print(steer)\n",
    "    return throttle, steer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d60580-7f48-4a15-943b-a5b0c97ce783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "efa619d9-ed85-43a9-91f4-14ed70bbb908",
   "metadata": {},
   "source": [
    "### Controlling the car"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe998bff-3ebb-4b48-9a10-1c6bba875a1c",
   "metadata": {},
   "source": [
    "# Function to control the car using predicted values\n",
    "def control_car(vehicle, throttle, steer):\n",
    "    control = carla.VehicleControl()\n",
    "    control.throttle = float(np.clip(throttle, 0, 1))\n",
    "    control.steer = float(np.clip(steer, -1, 1))\n",
    "    vehicle.apply_control(control)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bcd1c5-8981-4fae-9a2a-c22c360f5ea2",
   "metadata": {},
   "source": [
    "### Function for the camera listen and control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "466f578d-889b-40a0-ad27-b2b1ad4b144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback function to process each camera frame\n",
    "def on_image(image):\n",
    "    # Convert the CARLA image to numpy array\n",
    "    image.convert(carla.ColorConverter.Raw)\n",
    "    array_raw = np.frombuffer(image.raw_data, dtype=np.dtype(\"uint8\"))\n",
    "    array_bgra = np.reshape(array_raw, (image.height, image.width, 4))  # BGRA format\n",
    "    array_bgr = array_bgra[:, :, :3]  # Convert to BGRA\n",
    "    array_rgb = array_bgr[:, :, ::-1] # Convert to RGB\n",
    "\n",
    "    # Predict control based on the current frame\n",
    "    throttle, steer = predict_control(array_rgb)\n",
    "\n",
    "    # Apply control to the vehicle\n",
    "    control = carla.VehicleControl(throttle=float(throttle), steer=float(steer))\n",
    "    vehicle.apply_control(control)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5ee86e7c-8f33-440e-99a9-c61dbcf585cc",
   "metadata": {},
   "source": [
    "def image_callback(image):\n",
    "    image.convert(carla.ColorConverter.Raw)\n",
    "    image_array = np.frombuffer(image.raw_data, dtype=np.uint8).reshape((image.height, image.width, 4))[:, :, :3]\n",
    "    #image_array = np.frombuffer(image.raw_data, dtype=np.uint8).reshape((IMG_HEIGHT, IMG_WIDTH, 4))[:, :, :3]\n",
    "    image_queue.put(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbadfa43-a27f-44f8-b1f6-367182d8b5f6",
   "metadata": {},
   "source": [
    "### Function to move the car"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b9b3263-cc11-4dc4-b94e-2805c6837510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to move spectator with car\n",
    "def move_with_the_car():\n",
    "    spectator = world.get_spectator()\n",
    "    # Here the spectator is being positioned relative to the position of the car - Relative coordinate system\n",
    "    transform = carla.Transform(vehicle.get_transform().transform(carla.Location(x=-6,z=2)), \n",
    "                                vehicle.get_transform().rotation)\n",
    "    spectator.set_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b331968f-3111-48c9-a3dd-219be566d149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted, stopping the simulation.\n"
     ]
    }
   ],
   "source": [
    "# Connect to the Carla server\n",
    "# Generate a dataset with annotated cropped images and train on that\n",
    "client = carla.Client('localhost', 2000)\n",
    "client.set_timeout(5.0)\n",
    "\n",
    "# Load the world\n",
    "world = client.get_world()\n",
    "\n",
    "# Load the blueprint library\n",
    "blueprint_library = world.get_blueprint_library()\n",
    "\n",
    "# Set synchronous mode\n",
    "settings = world.get_settings()\n",
    "settings.synchronous_mode = True  # Enable synchronous mode\n",
    "settings.fixed_delta_seconds = 0.1\n",
    "world.apply_settings(settings)\n",
    "\n",
    "# Change weather - Talk about both methods in report\n",
    "weather = world.get_weather()\n",
    "weather.cloudiness = 100\n",
    "weather.fog_density = 0 # Use this if you only want to tweak a particular value and not change the other value\n",
    "#weather.precipitation = 20\n",
    "#weather.precipitation_deposits = 20\n",
    "#weather.snow_amount = 100\n",
    "#weather.snow_depth = 100\n",
    "#custom_weather = carla.WeatherParameters(    # Here other values may get overwritten\n",
    "    #cloudiness = 60,\n",
    "    #precipitation=50.0,           # Rain intensity percentage (0.0 to 100.0)\n",
    "    #precipitation_deposits=0.0,  # Water accumulation on surfaces (0.0 to 100.0)\n",
    "    #fog_density=0.0,             # Fog density percentage (0.0 to 100.0)\n",
    "    #fog_distance=100.0,           # Fog start distance in meters\n",
    "    #wetness=40.0,                 # Wetness of surfaces (0.0 to 100.0)\n",
    "    #ice_thickness=0.0,            # Thickness of ice on surfaces (0.0 to 100.0)\n",
    "    #snow_amount=100.0,             # Intensity of snowfall (0.0 to 100.0)\n",
    "    #snow_puddles=5.0,             # Water puddles from melted snow (0.0 to 100.0)\n",
    "    #snow_depth=8.0                # Depth of accumulated snow (0.0 to 100.0)\n",
    "#)\n",
    "world.set_weather(weather)\n",
    "\n",
    "# Spawn a vehicle\n",
    "vehicle_bp = blueprint_library.filter('vehicle.lincoln.mkz_2020')[0]\n",
    "spawn_points = world.get_map().get_spawn_points()\n",
    "spawn_point = spawn_points[1]\n",
    "shifted_spawn_point = carla.Transform(spawn_point.transform(carla.Location(x = 0)), \n",
    "                                      spawn_point.rotation)\n",
    "vehicle = world.spawn_actor(vehicle_bp, shifted_spawn_point)\n",
    "\n",
    "# Attach a camera to the vehicle\n",
    "camera_bp = blueprint_library.find('sensor.camera.rgb')\n",
    "camera_transform = carla.Transform(carla.Location(x=1.2, z=1.5))\n",
    "camera_bp.set_attribute(\"image_size_x\", \"640\")\n",
    "camera_bp.set_attribute(\"image_size_y\", \"480\")\n",
    "camera_bp.set_attribute(\"fov\", \"90\")\n",
    "camera = world.spawn_actor(camera_bp, camera_transform, attach_to=vehicle)\n",
    "\n",
    "#camera.listen(lambda image: image_callback(image))\n",
    "camera.listen(lambda image: on_image(image))\n",
    "\n",
    "#image_queue = queue.Queue()\n",
    "\n",
    "starting_time = time.time()\n",
    "# Define the duration in seconds\n",
    "duration = 120\n",
    "\n",
    "try:\n",
    "    # Main loop\n",
    "    while True:\n",
    "    #while time.time() - starting_time < duration:\n",
    "        move_with_the_car()\n",
    "        \n",
    "        # Tick the world to update sensor data\n",
    "        world.tick()\n",
    "\n",
    "        # # Get the latest image from the camera\n",
    "        # if not image_queue.empty():\n",
    "        #     image_array = image_queue.get()\n",
    "\n",
    "        #     # Predict control values\n",
    "        #     throttle, steer = predict_control(image_array)\n",
    "\n",
    "        #     # Apply control to the vehicle\n",
    "        #     control_car(vehicle, throttle, steer)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Interrupted, stopping the simulation.\")\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()\n",
    "        \n",
    "finally:\n",
    "    # Clean up actors\n",
    "    for actor in world.get_actors().filter('*vehicle*'):\n",
    "        actor.destroy()\n",
    "    for sensor in world.get_actors().filter('*sensor*'):\n",
    "        sensor.destroy()\n",
    "\n",
    "    # Restore settings\n",
    "    settings.synchronous_mode = False\n",
    "    world.apply_settings(settings)\n",
    "\n",
    "    # Restore weather\n",
    "    world.set_weather(carla.WeatherParameters.Default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47b26b2-07c5-49a4-9e6b-0baf3c0c1bfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7413e8b-825e-4e17-844b-431090bd8ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7046"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean up actors\n",
    "for actor in world.get_actors().filter('*vehicle*'):\n",
    "    actor.destroy()\n",
    "for sensor in world.get_actors().filter('*sensor*'):\n",
    "    sensor.destroy()\n",
    "\n",
    "# Restore settings\n",
    "settings.synchronous_mode = False\n",
    "world.apply_settings(settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5accc4-b234-4ef1-b154-ab3a38d44452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c9035f-c675-477a-bcd4-b33347ee1bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ed5fdb-f26d-4809-8b1a-6ae3836f202b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7effaddb-caea-4a39-acfd-66cc879b8e83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9731693-1a74-458b-8746-3f5c8ea46ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
